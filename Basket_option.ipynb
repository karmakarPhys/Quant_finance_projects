{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33514953-86b4-4335-893d-2d1df728a15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Price (2 assets): 5.7803\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example parameters\n",
    "S0 = [100, 120]\n",
    "sigma = [0.2, 0.25]\n",
    "rho = np.array([[1.0, 0.1], [0.1, 1.0]])\n",
    "w = [0.5, 0.5]\n",
    "r = 0.05\n",
    "T = 1.0\n",
    "K = 110\n",
    "\n",
    "def asian_basket_mc(S0, sigma, rho, w, r, T, K, option_type='call', N_steps=50, N_sim=2000, seed=42):\n",
    "    \"\"\"\n",
    "    Asian basket option price using Monte Carlo simulation (2 assets).\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    S0 = np.array(S0)\n",
    "    sigma = np.array(sigma)\n",
    "    w = np.array(w)\n",
    "    n_assets = 2\n",
    "    dt = T / N_steps\n",
    "    \n",
    "    # Cholesky decomposition for correlation\n",
    "    L = np.linalg.cholesky(rho)\n",
    "    \n",
    "    # Simulate paths\n",
    "    payoffs = np.zeros(N_sim)\n",
    "    for sim in range(N_sim):\n",
    "        Z = np.random.randn(N_steps, n_assets)\n",
    "        correlated_Z = Z @ L.T\n",
    "\n",
    "        S = np.zeros((N_steps + 1, n_assets))\n",
    "        S[0] = S0\n",
    "\n",
    "        for t in range(1, N_steps + 1):\n",
    "            S[t] = S[t-1] * np.exp((r - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * correlated_Z[t-1])\n",
    "\n",
    "        basket_avg = np.mean(S @ w) #creates S.w = a column vector of size [N_steps, 1]\n",
    "        \n",
    "        if option_type.lower() == 'call':\n",
    "            payoffs[sim] = max(basket_avg - K, 0)\n",
    "        else:\n",
    "            payoffs[sim] = max(K - basket_avg, 0)\n",
    "    \n",
    "    price = np.exp(-r * T) * np.mean(payoffs)\n",
    "    return price\n",
    "\n",
    "price_mc = asian_basket_mc(S0, sigma, rho, w, r, T, K)\n",
    "print(f\"Monte Carlo Price (2 assets): {price_mc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da32dd5b-f052-4044-9ec8-01434339d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Moment Matching Price (2 assets): 5.3648\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def asian_basket_three_moment(S0, sigma, rho, w, r, T, K, option_type='call'):\n",
    "    \"\"\"\n",
    "    Asian basket option price using 3-moment matching (2 assets).\n",
    "    \"\"\"\n",
    "    S0 = np.array(S0)\n",
    "    sigma = np.array(sigma)\n",
    "    w = np.array(w)\n",
    "    \n",
    "    # Covariance matrix\n",
    "    cov_matrix = np.outer(sigma, sigma) * rho\n",
    "\n",
    "    # Approximate moments of arithmetic average\n",
    "    # Mean\n",
    "    mu_i = S0 * np.exp(r * T)\n",
    "    mu_A = np.sum(w * mu_i)\n",
    "    \n",
    "    # Variance\n",
    "    var_matrix = np.zeros((2, 2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            cov_ij = cov_matrix[i, j]\n",
    "            var_matrix[i, j] = S0[i] * S0[j] * (np.exp(cov_ij * T) - 1) * np.exp(2 * r * T)\n",
    "    var_A = np.sum(w[:, None] * w[None, :] * var_matrix)\n",
    "    \n",
    "    # Skewness\n",
    "    skew_matrix = np.zeros((2, 2, 2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for k in range(2):\n",
    "                cov_ij = cov_matrix[i, j]\n",
    "                cov_ik = cov_matrix[i, k]\n",
    "                cov_jk = cov_matrix[j, k]\n",
    "                skew_matrix[i, j, k] = (S0[i] * S0[j] * S0[k] *\n",
    "                                         (np.exp(cov_ij + cov_ik + cov_jk) * T - 3*np.exp(cov_ij*T) + 2*np.exp(0)))\n",
    "    skew_A = np.sum(w[:, None, None] * w[None, :, None] * w[None, None, :] * skew_matrix)\n",
    "\n",
    "    # Approximate using a 3-moment lognormal (Cornish-Fisher approximation)\n",
    "    # Compute adjusted d1, d2\n",
    "    # Using simplified shifted lognormal approximation:\n",
    "    sigma_adj = np.sqrt(np.log(var_A / mu_A**2 + 1))\n",
    "    mu_adj = np.log(mu_A) - 0.5 * sigma_adj**2\n",
    "    # Apply skew adjustment (Cornish-Fisher)\n",
    "    z = (np.log(mu_A / K) - mu_adj) / sigma_adj\n",
    "    skew_adj = skew_A / (var_A ** 1.5)\n",
    "    z_cf = z + (1/6)*(z**2 - 1)*skew_adj\n",
    "\n",
    "    if option_type.lower() == 'call':\n",
    "        price = np.exp(-r*T) * (mu_A * norm.cdf(z_cf) - K * norm.cdf(z_cf - sigma_adj))\n",
    "    else:\n",
    "        price = np.exp(-r*T) * (K * norm.cdf(-(z_cf - sigma_adj)) - mu_A * norm.cdf(-z_cf))\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Example usage\n",
    "S0 = [100, 120]\n",
    "sigma = [0.2, 0.25]\n",
    "rho = np.array([[1.0, 0.3], [0.3, 1.0]])\n",
    "w = [0.5, 0.5]\n",
    "r = 0.05\n",
    "T = 1.0\n",
    "K = 110\n",
    "\n",
    "price_3mm = asian_basket_three_moment(S0, sigma, rho, w, r, T, K)\n",
    "print(f\"3-Moment Matching Price (2 assets): {price_3mm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e8b0bd-a223-4f9f-923c-9a8ae8f56335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian Basket Option Pricing using Three-Moment Matching\n",
      "Mean (m1): 103.8288\n",
      "Variance (m2): 425.7749\n",
      "Skewness: 13.0579\n",
      "Approximate Call Price: 2.3841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Parameters ===\n",
    "S0 = np.array([100, 95])          # Initial prices of the two assets\n",
    "sigma = np.array([0.2, 0.25])     # Volatilities\n",
    "rho = 0.6                         # Correlation between the two assets\n",
    "r = 0.05                          # Risk-free rate\n",
    "T = 2.0                           # Maturity\n",
    "t_obs = np.array([0.5, 1.0, 1.5, 2.0])   # Observation dates\n",
    "N = len(t_obs)\n",
    "w = np.array([0.5, 0.5])          # Equal weights\n",
    "K = 100                           # Strike\n",
    "\n",
    "# === Correlation matrix ===\n",
    "corr = np.array([[1.0, rho],\n",
    "                 [rho, 1.0]])\n",
    "\n",
    "# === Step 1: Compute first moment (mean) ===\n",
    "m1 = 0.0\n",
    "for t in t_obs:\n",
    "    for i in range(2):\n",
    "        m1 += w[i] * S0[i] * np.exp(r * t)\n",
    "m1 /= N  # average over time\n",
    "\n",
    "# === Step 2: Compute second moment (variance) ===\n",
    "m2 = 0.0\n",
    "for k in range(N):\n",
    "    for l in range(N):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                cov_ij = S0[i] * S0[j] * np.exp(r * (t_obs[k] + t_obs[l])) * \\\n",
    "                         (np.exp(corr[i, j] * sigma[i] * sigma[j] * min(t_obs[k], t_obs[l])) - 1)\n",
    "                m2 += w[i] * w[j] * cov_ij\n",
    "m2 /= N**2  # time averaging\n",
    "varA = m2\n",
    "\n",
    "# === Step 3: Compute third central moment (approximate skewness) ===\n",
    "m3 = 0.0\n",
    "for k in range(N):\n",
    "    for l in range(N):\n",
    "        for m in range(N):\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    for p in range(2):\n",
    "                        cov3 = S0[i]*S0[j]*S0[p]*np.exp(r*(t_obs[k]+t_obs[l]+t_obs[m])) * \\\n",
    "                               (np.exp((corr[i,j]*sigma[i]*sigma[j] +\n",
    "                                        corr[i,p]*sigma[i]*sigma[p] +\n",
    "                                        corr[j,p]*sigma[j]*sigma[p]) *\n",
    "                                        min(t_obs[k], t_obs[l], t_obs[m])) - 1)\n",
    "                        m3 += w[i]*w[j]*w[p]*cov3\n",
    "m3 /= N**3\n",
    "skewA = m3 / (varA ** 1.5)\n",
    "\n",
    "# === Step 4: Fit a skewed lognormal using Cornish-Fisher expansion ===\n",
    "# Variance-to-mean lognormal parameters\n",
    "sigma_L = np.sqrt(np.log(1 + varA / (m1**2)))\n",
    "mu_L = np.log(m1) - 0.5 * sigma_L**2\n",
    "\n",
    "# Cornish-Fisher adjustment\n",
    "d1 = (np.log(m1 / K) + 0.5 * sigma_L**2) / sigma_L\n",
    "d2 = d1 - sigma_L\n",
    "\n",
    "# Adjust for skewness\n",
    "d1_CF = d1 + (skewA / 6) * (d1**2 - 1)\n",
    "d2_CF = d2 + (skewA / 6) * (d2**2 - 1)\n",
    "\n",
    "# === Step 5: Approximate price ===\n",
    "price = np.exp(-r * T) * (m1 * norm.cdf(d1_CF) - K * norm.cdf(d2_CF))\n",
    "\n",
    "# === Output ===\n",
    "print(\"Asian Basket Option Pricing using Three-Moment Matching\")\n",
    "print(f\"Mean (m1): {m1:.4f}\")\n",
    "print(f\"Variance (m2): {varA:.4f}\")\n",
    "print(f\"Skewness: {skewA:.4f}\")\n",
    "print(f\"Approximate Call Price: {price:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fffae51-49a0-44cc-9b32-3b5a5c059e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian Basket Option Pricing using Monte Carlo Simulation\n",
      "Estimated Price: 5.4354\n",
      "Standard Error: 0.0189\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === Parameters ===\n",
    "S0 = np.array([100, 95])          # Initial prices of the two assets\n",
    "sigma = np.array([0.2, 0.25])     # Volatilities\n",
    "rho = 0.6                         # Correlation between the two assets\n",
    "r = 0.05                          # Risk-free rate\n",
    "T = 2.0                           # Maturity\n",
    "t_obs = np.array([0.5, 1.0, 1.5, 2.0])   # Observation dates\n",
    "N = len(t_obs)\n",
    "w = np.array([0.5, 0.5])          # Equal weights\n",
    "K = 100                           # Strike\n",
    "n_paths = 200000                  # Monte Carlo paths\n",
    "n_assets = 2                      # Two underlying assets\n",
    "\n",
    "# === Step 1: Correlation matrix and Cholesky ===\n",
    "corr = np.array([[1.0, rho],\n",
    "                 [rho, 1.0]])\n",
    "L = np.linalg.cholesky(corr)\n",
    "\n",
    "# === Step 2: Simulate correlated GBM paths ===\n",
    "dt_list = np.diff(np.insert(t_obs, 0, 0.0))  # time intervals between obs\n",
    "S = np.zeros((n_paths, N, n_assets))\n",
    "S[:, 0, :] = S0\n",
    "\n",
    "for n in range(1, N):\n",
    "    dt = dt_list[n]\n",
    "    # Generate correlated random shocks\n",
    "    Z = np.random.normal(size=(n_paths, n_assets))\n",
    "    dW = Z @ L.T\n",
    "    drift = (r - 0.5 * sigma**2) * dt\n",
    "    diffusion = sigma * np.sqrt(dt) * dW\n",
    "    S[:, n, :] = S[:, n-1, :] * np.exp(drift + diffusion)\n",
    "\n",
    "# === Step 3: Compute basket value at each observation date ===\n",
    "basket_values = np.dot(S, w)  # shape: (n_paths, N)\n",
    "\n",
    "# === Step 4: Compute average basket price per path ===\n",
    "basket_avg = np.mean(basket_values, axis=1)\n",
    "\n",
    "# === Step 5: Compute discounted payoff ===\n",
    "payoffs = np.exp(-r * T) * np.maximum(basket_avg - K, 0.0)\n",
    "\n",
    "# === Step 6: Monte Carlo estimate ===\n",
    "price_MC = np.mean(payoffs)\n",
    "stderr_MC = np.std(payoffs) / np.sqrt(n_paths)\n",
    "\n",
    "# === Output ===\n",
    "print(\"Asian Basket Option Pricing using Monte Carlo Simulation\")\n",
    "print(f\"Estimated Price: {price_MC:.4f}\")\n",
    "print(f\"Standard Error: {stderr_MC:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03c464a-3e5c-4aa6-9309-3f7ea5db5c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian Basket Option Pricing using Two-Moment Matching\n",
      "Mean (m1): 103.8288\n",
      "Variance (m2): 425.7749\n",
      "Approximate Call Price: 9.0919\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Parameters (same as MC) ===\n",
    "S0 = np.array([100, 95])          # Initial prices\n",
    "sigma = np.array([0.2, 0.25])     # Volatilities\n",
    "rho = 0.6                         # Correlation\n",
    "r = 0.05                          # Risk-free rate\n",
    "T = 2.0                           # Maturity\n",
    "t_obs = np.array([0.5, 1.0, 1.5, 2.0])  # Observation dates\n",
    "N = len(t_obs)\n",
    "w = np.array([0.5, 0.5])          # Equal weights\n",
    "K = 100                           # Strike\n",
    "\n",
    "# === Correlation matrix ===\n",
    "corr = np.array([[1.0, rho],\n",
    "                 [rho, 1.0]])\n",
    "\n",
    "# === Step 1: Mean of average basket ===\n",
    "m1 = 0.0\n",
    "for t in t_obs:\n",
    "    for i in range(2):\n",
    "        m1 += w[i] * S0[i] * np.exp(r * t)\n",
    "m1 /= N\n",
    "\n",
    "# === Step 2: Variance of average basket ===\n",
    "m2 = 0.0\n",
    "for k in range(N):\n",
    "    for l in range(N):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                cov_ij = S0[i]*S0[j]*np.exp(r*(t_obs[k]+t_obs[l])) * (\n",
    "                    np.exp(corr[i, j]*sigma[i]*sigma[j]*min(t_obs[k], t_obs[l])) - 1\n",
    "                )\n",
    "                m2 += w[i]*w[j]*cov_ij\n",
    "m2 /= N**2  # average over time pairs\n",
    "\n",
    "varA = m2\n",
    "stdA = np.sqrt(varA)\n",
    "\n",
    "# === Step 3: Lognormal parameters ===\n",
    "sigma_L = np.sqrt(np.log(1 + varA / (m1**2)))\n",
    "mu_L = np.log(m1) - 0.5 * sigma_L**2\n",
    "\n",
    "# === Step 4: Black–Scholes–type approximation ===\n",
    "d1 = (np.log(m1 / K) + 0.5 * sigma_L**2) / sigma_L\n",
    "d2 = d1 - sigma_L\n",
    "\n",
    "price = np.exp(-r * T) * (m1 * norm.cdf(d1) - K * norm.cdf(d2))\n",
    "\n",
    "# === Output ===\n",
    "print(\"Asian Basket Option Pricing using Two-Moment Matching\")\n",
    "print(f\"Mean (m1): {m1:.4f}\")\n",
    "print(f\"Variance (m2): {varA:.4f}\")\n",
    "print(f\"Approximate Call Price: {price:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622a3795-80d8-43fb-902b-f8ac93f6178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simulate_asian_basket_mc_time_dep(\n",
    "    S0, vol_times_list, vol_vals_list, rho, w, r, t_obs, K,\n",
    "    n_paths=200000, seed=42, option_type='call'\n",
    "):\n",
    "    \"\"\"\n",
    "    Monte Carlo for a 2-asset Asian basket with piecewise-constant vol term structures.\n",
    "    - S0: array-like, shape (n_assets,)\n",
    "    - vol_times_list: list of arrays; vol_times_list[i] are boundary times for asset i (including 0)\n",
    "    - vol_vals_list: list of arrays; vol_vals_list[i] are vol values on intervals between vol_times (len = len(vol_times)-1)\n",
    "    - rho: correlation matrix (n_assets x n_assets)\n",
    "    - w: weights array, shape (n_assets,)\n",
    "    - r: risk-free rate (assumed constant here; can be time-dependent if wanted)\n",
    "    - t_obs: array of observation times (increasing)\n",
    "    - K: strike\n",
    "    - n_paths, seed: MC settings\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    S0 = np.array(S0)\n",
    "    w = np.array(w)\n",
    "    t_obs = np.array(t_obs)\n",
    "    n_assets = len(S0)\n",
    "    n_obs = len(t_obs)\n",
    "\n",
    "    # Precompute integrated variances and covariances between observation times\n",
    "    # For each asset i and interval (t_{k-1}, t_k], compute var_i(k) = ∫_{t_{k-1}}^{t_k} sigma_i(u)^2 du\n",
    "    # For covariances between assets i,j over interval use ∫ sigma_i(u) sigma_j(u) du times rho_ij\n",
    "    dt_intervals = np.diff(np.insert(t_obs, 0, 0.0))  # interval lengths where we advance from previous obs to next\n",
    "\n",
    "    # Build per-interval sigma_i (value used on that interval) by mapping piecewise structure to t_obs intervals\n",
    "    sigma_intervals = np.zeros((n_assets, n_obs))  # sigma_intervals[i,k] used on interval k (0..n_obs-1)\n",
    "    for i in range(n_assets):\n",
    "        times = vol_times_list[i]   # e.g. [0.0, 0.5, 1.0, 2.0]\n",
    "        vals = vol_vals_list[i]     # len = len(times)-1\n",
    "        # For each interval (previous_obs, obs_k], pick sigma value appropriate (we assume piecewise const aligned or we choose value on midpoint)\n",
    "        for k in range(n_obs):\n",
    "            t_left = 0.0 if k == 0 else t_obs[k-1]\n",
    "            t_right = t_obs[k]\n",
    "            # If piecewise constant but boundaries don't align exactly with t_left/t_right, we compute average sigma^2 over the interval:\n",
    "            # we'll compute integral of sigma^2(u) on [t_left, t_right] by summing contributions on overlapping piecewise segments\n",
    "            # but for simulation we only need sqrt of integral; we'll compute effective sigma * sqrt(dt) below.\n",
    "            # To keep mapping simple, store the piecewise data and compute integrals directly in next step.\n",
    "            sigma_intervals[i, k] = np.nan  # placeholder\n",
    "\n",
    "    # Compute integrated covariances per interval: for interval k, compute\n",
    "    # Var contribution for asset i: var_i_k = ∫_{t_{k-1}}^{t_k} sigma_i(u)^2 du\n",
    "    var_interval = np.zeros((n_assets, n_obs))\n",
    "    cov_interval = np.zeros((n_assets, n_assets, n_obs))\n",
    "    for k in range(n_obs):\n",
    "        a = 0.0 if k == 0 else t_obs[k-1]\n",
    "        b = t_obs[k]\n",
    "        for i in range(n_assets):\n",
    "            # integrate sigma_i(u)^2 over [a,b]\n",
    "            times = vol_times_list[i]\n",
    "            vals = vol_vals_list[i]\n",
    "            integral = 0.0\n",
    "            for m in range(len(vals)):\n",
    "                seg_left, seg_right = times[m], times[m+1]\n",
    "                inter_left = max(a, seg_left)\n",
    "                inter_right = min(b, seg_right)\n",
    "                if inter_right > inter_left:\n",
    "                    integral += vals[m]**2 * (inter_right - inter_left)\n",
    "            var_interval[i, k] = integral\n",
    "        for i in range(n_assets):\n",
    "            for j in range(n_assets):\n",
    "                # integrate sigma_i(u)*sigma_j(u) over [a,b]\n",
    "                integral = 0.0\n",
    "                # simple approach: iterate over partition given by union of times of i and j\n",
    "                times_union = np.union1d(vol_times_list[i], vol_times_list[j])\n",
    "                for m in range(len(times_union)-1):\n",
    "                    seg_l, seg_r = times_union[m], times_union[m+1]\n",
    "                    inter_left = max(a, seg_l)\n",
    "                    inter_right = min(b, seg_r)\n",
    "                    if inter_right > inter_left:\n",
    "                        # find sigma_i on this subsegment\n",
    "                        # find index of segment for asset i\n",
    "                        idx_i = np.searchsorted(vol_times_list[i], (seg_l+seg_r)/2.0) - 1\n",
    "                        idx_j = np.searchsorted(vol_times_list[j], (seg_l+seg_r)/2.0) - 1\n",
    "                        sid = vol_vals_list[i][max(0, min(idx_i, len(vol_vals_list[i])-1))]\n",
    "                        sjd = vol_vals_list[j][max(0, min(idx_j, len(vol_vals_list[j])-1))]\n",
    "                        integral += sid * sjd * (inter_right - inter_left)\n",
    "                cov_interval[i, j, k] = integral * (rho[i, j] if i != j else 1.0)\n",
    "\n",
    "    # Now simulate: we can simulate increments of log S exactly per interval:\n",
    "    # ln S_i(t_k) = ln S_i(t_{k-1}) + (r - 0.5 * (var_i_k/dt_k)) * dt_k + normal with variance var_i_k\n",
    "    # But simpler: simulate correlated normals with covariance matrix Sigma_k where Sigma_k[i,i] = var_interval[i,k], Sigma_k[i,j] = cov_interval[i,j,k]\n",
    "    # For each k generate multivariate normal N(0, Sigma_k)\n",
    "    from numpy.linalg import cholesky\n",
    "\n",
    "    # Precompute cholesky for each interval k\n",
    "    chol_k = []\n",
    "    for k in range(n_obs):\n",
    "        Sigma_k = np.zeros((n_assets, n_assets))\n",
    "        for i in range(n_assets):\n",
    "            for j in range(n_assets):\n",
    "                Sigma_k[i, j] = cov_interval[i, j, k]\n",
    "        # numerical fix for PSD\n",
    "        eps = 1e-12\n",
    "        Sigma_k += np.eye(n_assets) * eps\n",
    "        chol_k.append(np.linalg.cholesky(Sigma_k))\n",
    "\n",
    "    # allocate S_paths at observation times\n",
    "    S_paths = np.zeros((n_paths, n_obs, n_assets))\n",
    "    S_paths[:, 0, :] = S0  # starting value at t0? We'll simulate increments from 0->t_obs[0] etc.\n",
    "    # actually we need S at each observation time: do step-by-step\n",
    "    lnS = np.log(np.tile(S0, (n_paths,1)))  # shape (n_paths, n_assets)\n",
    "\n",
    "    for k in range(n_obs):\n",
    "        Lk = chol_k[k]\n",
    "        # draw n_paths multivariate normals: Z shape (n_paths, n_assets)\n",
    "        Z = np.random.normal(size=(n_paths, n_assets))\n",
    "        # correlated normals with cov Sigma_k: increments = Z @ Lk.T\n",
    "        increments = Z @ Lk.T  # shape (n_paths, n_assets)\n",
    "        # drift term for each asset i: r*dt - 0.5 * (var_interval[i,k])\n",
    "        dt_k = (0.0 if k==0 else t_obs[k-1])  # not used; we only need integrated variance var_interval\n",
    "        # For exact GBM log increment: ln S(t_k) = ln S(t_{k-1}) + int r dt - 0.5 * var_i_k + increment_i\n",
    "        # assume constant r -> int_0^{delta} r du = r*(b-a)\n",
    "        a = 0.0 if k==0 else t_obs[k-1]\n",
    "        b = t_obs[k]\n",
    "        int_r = r * (b - a)\n",
    "        drift = int_r - 0.5 * var_interval[:, k]  # shape (n_assets,)\n",
    "        # apply increment to all paths\n",
    "        lnS = lnS + drift + increments\n",
    "        S_now = np.exp(lnS)\n",
    "        S_paths[:, k, :] = S_now\n",
    "\n",
    "    # basket values and payoff\n",
    "    basket_vals = S_paths @ w  # (n_paths, n_obs)\n",
    "    basket_avg = basket_vals.mean(axis=1)\n",
    "    T = t_obs[-1]\n",
    "    payoffs = np.exp(-r * T) * np.maximum(basket_avg - K, 0.0) if option_type == 'call' else np.exp(-r*T)*np.maximum(K - basket_avg, 0.0)\n",
    "    price = payoffs.mean()\n",
    "    stderr = payoffs.std(ddof=1)/np.sqrt(n_paths)\n",
    "    return price, stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b59686-fef7-49b4-b76f-b8a1a6c99f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def two_moment_matching_time_dep(S0, vol_times_list, vol_vals_list, rho, w, r, t_obs, K):\n",
    "    \"\"\"\n",
    "    Compute 2-moment matching price for basket average with time-dependent vols.\n",
    "    Inputs similar to MC function.\n",
    "    \"\"\"\n",
    "    S0 = np.array(S0)\n",
    "    w = np.array(w)\n",
    "    t_obs = np.array(t_obs)\n",
    "    n_assets = len(S0)\n",
    "    N = len(t_obs)\n",
    "    # Precompute integrals C_ij(tk, tl)\n",
    "    # We'll compute for all pairs (k,l)\n",
    "    C = np.zeros((n_assets, n_assets, N, N))\n",
    "    for k in range(N):\n",
    "        for l in range(N):\n",
    "            tmin = min(t_obs[k], t_obs[l])\n",
    "            a = 0.0\n",
    "            b = tmin\n",
    "            for i in range(n_assets):\n",
    "                for j in range(n_assets):\n",
    "                    # integrate sigma_i(u)*sigma_j(u) over [a,b]\n",
    "                    integral = 0.0\n",
    "                    times_union = np.union1d(vol_times_list[i], vol_times_list[j])\n",
    "                    for m in range(len(times_union)-1):\n",
    "                        seg_l = times_union[m]; seg_r = times_union[m+1]\n",
    "                        inter_left = max(a, seg_l)\n",
    "                        inter_right = min(b, seg_r)\n",
    "                        if inter_right > inter_left:\n",
    "                            # pick sigma_i on midpoint\n",
    "                            idx_i = np.searchsorted(vol_times_list[i], 0.5*(seg_l+seg_r)) - 1\n",
    "                            idx_j = np.searchsorted(vol_times_list[j], 0.5*(seg_l+seg_r)) - 1\n",
    "                            si = vol_vals_list[i][max(0, min(idx_i, len(vol_vals_list[i])-1))]\n",
    "                            sj = vol_vals_list[j][max(0, min(idx_j, len(vol_vals_list[j])-1))]\n",
    "                            integral += si * sj * (inter_right - inter_left)\n",
    "                    C[i,j,k,l] = rho[i,j] * integral\n",
    "\n",
    "    # Compute m1\n",
    "    m1 = 0.0\n",
    "    for k in range(N):\n",
    "        for i in range(n_assets):\n",
    "            m1 += w[i] * S0[i] * np.exp(r * t_obs[k])\n",
    "    m1 /= N\n",
    "\n",
    "    # Compute Var(A)\n",
    "    varA = 0.0\n",
    "    for k in range(N):\n",
    "        for l in range(N):\n",
    "            for i in range(n_assets):\n",
    "                for j in range(n_assets):\n",
    "                    cov_ij = S0[i]*S0[j]*np.exp(r*(t_obs[k]+t_obs[l])) * (np.exp(C[i,j,k,l]) - 1.0)\n",
    "                    varA += w[i]*w[j]*cov_ij\n",
    "    varA /= N**2\n",
    "\n",
    "    # Match lognormal\n",
    "    sigma_A = np.sqrt(np.log(1 + varA / (m1**2)))\n",
    "    mu_A = np.log(m1) - 0.5 * sigma_A**2\n",
    "    d1 = (np.log(m1 / K) + 0.5 * sigma_A**2) / sigma_A\n",
    "    d2 = d1 - sigma_A\n",
    "    price = np.exp(-r * t_obs[-1]) * (m1 * norm.cdf(d1) - K * norm.cdf(d2))\n",
    "    return price, m1, varA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43b997d-b3f7-4912-b859-b8a51ad24438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-moment matching price: 8.584954764838338\n",
      "MC price: 8.518949279462854 stderr: 0.027726592386275246\n"
     ]
    }
   ],
   "source": [
    "# Example setup (2 assets)\n",
    "S0 = [100, 95]\n",
    "# Suppose these are implied ATM vols for total maturities [0.5, 1.0, 1.5, 2.0]\n",
    "imp_mats = np.array([0.5, 1.0, 1.5, 2.0])\n",
    "imp_vols_asset1 = np.array([0.18, 0.19, 0.195, 0.2])\n",
    "imp_vols_asset2 = np.array([0.22, 0.225, 0.23, 0.235])\n",
    "\n",
    "# Build piecewise instantaneous vol per asset via forward variance decomposition\n",
    "def piecewise_instantaneous_from_imp(imp_times, imp_vols):\n",
    "    # imp_vols are Black implied vol (annualized) at imp_times\n",
    "    V = imp_vols**2 * imp_times  # cumulative variance at each maturity\n",
    "    times = np.concatenate(([0.0], imp_times))\n",
    "    vals = []\n",
    "    for k in range(len(imp_times)):\n",
    "        dt = imp_times[k] - (imp_times[k-1] if k>0 else 0.0)\n",
    "        forward_var = (V[k] - (V[k-1] if k>0 else 0.0)) / dt\n",
    "        vals.append(np.sqrt(max(forward_var, 0.0)))  # instantaneous vol on (t_{k-1}, t_k]\n",
    "    return times, np.array(vals)\n",
    "\n",
    "vol_times_list = []\n",
    "vol_vals_list = []\n",
    "for impv in [imp_vols_asset1, imp_vols_asset2]:\n",
    "    times, vals = piecewise_instantaneous_from_imp(imp_mats, impv)\n",
    "    vol_times_list.append(times)\n",
    "    vol_vals_list.append(vals)\n",
    "\n",
    "rho = np.array([[1.0, 0.6],[0.6,1.0]])\n",
    "w = [0.5,0.5]\n",
    "r = 0.05\n",
    "t_obs = np.array([0.5,1.0,1.5,2.0])\n",
    "K = 100\n",
    "\n",
    "# Two moment price\n",
    "price_2mm, m1, varA = two_moment_matching_time_dep(S0, vol_times_list, vol_vals_list, rho, w, r, t_obs, K)\n",
    "print(\"Two-moment matching price:\", price_2mm)\n",
    "\n",
    "# MC price\n",
    "price_mc, stderr = simulate_asian_basket_mc_time_dep(S0, vol_times_list, vol_vals_list, rho, w, r, t_obs, K, n_paths=200000)\n",
    "print(\"MC price:\", price_mc, \"stderr:\", stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd1202-b753-4cb3-8240-0aee67b75700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
